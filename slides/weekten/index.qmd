---
title: "Finite State Automata"
description: "Grasp computing with limited resources"
date: "2025-10-27"
date-format: long
author: Gregory M. Kapfhammer
execute:
  echo: true
format:
  live-revealjs:
    completion: true
    theme: default
    css: ../css/styles.css
    history: false
    scrollable: true
    transition: slide
    highlight-style: github
    footer: "Proofgrammers"
---

# Learning objectives

::: {.fragment .callout-note icon=true title="Learning Objectives for Theoretical Machines"}

- **CS-204-1**: Use both intuitive analysis and theoretical proof
techniques to correctly distinguish between problems that are tractable,
intractable, and uncomputable.
- **CS-204-2**: Correctly use one or more variants of the Turing machine
(TM) abstraction to both describe and analyze the solution to a
computational problem.
- **CS-204-3**: Correctly use one or more variants of the finite state
machine (FSM) abstraction to describe and analyze the solution to a
computational problem.
- **CS-204-4**: Use a formal proof technique to correctly classify a
problem according to whether or not it is in the P, NP, NP-Hard, and/or
NP-Complete complexity class(es).
- **CS-204-5**: Apply insights from theoretical proofs concerning the
limits of either program feasibility or complexity to the implementation
of both correct and efficient real-world Python programs.

:::

# Finite state automata are simplified Turing machines! Interesting!

::: {.fragment .boxed-content style="font-size: 0.8em;"}

{{< iconify fa6-solid lightbulb >}} Finite automata help with learning objective
**CS-204-3**, in which you learn about finite state machines (FSMs) and their
computational power. **Let's explore how constraints affect computability! Why
is it beneficial to make these constraints? How does the FSM connect to
practical computing?**

:::

## What are finite automata?

::: {.incremental style="margin-top: -0.25em; font-size: 0.925em;"}

- {{< iconify fa6-solid microchip >}} **Finite automata**: Special, restricted
case of Turing machines
- {{< iconify fa6-solid arrow-right >}} **Key restrictions**: Head only moves
right, never edits tape
- {{< iconify fa6-solid stop >}} **Termination**: Blank symbol ends input
processing
- {{< iconify fa6-solid microscope >}} **Question**: What problems can finite
automata solve?
- {{< iconify fa6-solid rocket >}} **Question**: How do they aid agents and
regular expressions?

:::

::: {.fragment .fade .boxed-content style="font-size: 0.8em;"}

**Finite automata model computation with severely limited resources**! No memory
beyond a fixed number of states and no ability to revisit previous input.
Despite these constraints, they remain useful for pattern matching, lexical
analysis, and network protocol verification. Although restricted, there are
**deterministic** and **nondeterministic** versions. Let's explore in detail!

:::

## Deterministic finite automata

::: {.incremental style="margin-top: -0.5em; font-size: 0.9em;"}

- **Components of a deterministic finite automaton (DFA)**:
    - Alphabet of symbols (including blank)
    - Finite set of states (start, accept, reject)
    - Transition function: $(q, x) \rightarrow q'$
- **Computation**: read symbol, transition to new state, move right
- **Always halts**: after at most $n$ steps for input length $n$
- **Deterministic**: exactly one possible transition from each state

:::

::: {.fragment .fade .boxed-content style="font-size: 0.8em;"}

{{< iconify fa6-solid lightbulb >}} **DFAs are the simplest computational
model**! They can recognize patterns in strings but cannot count unbounded
values or maintain memory.

:::

## Understanding simple DFAs

::: {.fragment .boxed-content style="margin-top: 0.25em; font-size: 0.9em;"}

- Nodes represents states, arrows are transitions on input symbols
- Acceptance state(s) indicated by double circles on nodes
- **Implicit transitions**: unspecified transitions go to `qreject`
- DFA is visually similar to the Turing machine's state diagram
- Behavior of two simple DFAs:
    - **`containsGAGA`**: accepts strings with substring "GAGA"
    - **`multipleOf5`**: accepts decimal numbers divisible by 5
- {{< iconify fa6-solid lightbulb >}} **What do they look like? How do they work? Key benefits?**

:::

## DFA examples: `containsGAGA` {transition="convex"}

![DFA for `containsGAGA`](09-finite-automata_1.png)

## DFA examples: `multipleOf5` {transition="convex"}

![DFA for `multipleOf5`](09-finite-automata_0.png)

## Implementing a simple DFA simulator

```{python}
def simulate_dfa(transitions: dict, start: str, accept: set,
                 input_string: str) -> bool:
    """Simulate a DFA on an input string."""
    current_state = start
    for symbol in input_string:
        if (current_state, symbol) in transitions:
            current_state = transitions[(current_state, symbol)]
        else:
            return False
    return current_state in accept

# DFA for strings ending in 'AB'
transitions = {
    ('q0', 'A'): 'q1', ('q0', 'B'): 'q0',
    ('q1', 'A'): 'q1', ('q1', 'B'): 'q2',
    ('q2', 'A'): 'q1', ('q2', 'B'): 'q0'
}
accept = {'q2'}

print(f"'AAAB' accepted: {simulate_dfa(transitions, 'q0', accept, 'AAAB')}")
print(f"'ABAB' accepted: {simulate_dfa(transitions, 'q0', accept, 'ABAB')}")
print(f"'ABBA' accepted: {simulate_dfa(transitions, 'q0', accept, 'ABBA')}")
```

# Define nondeterministic finite automata (NFA)

::: {.incremental style="margin-top: -0.5em; font-size: 0.8em;"}

- {{< iconify fa6-solid clone >}} **Nondeterminism**: multiple possible
transitions from same state
- {{< iconify fa6-solid code-branch >}} **Epsilon transitions**: can
transition without reading input
- {{< iconify fa6-solid check >}} **Acceptance**: accept if **any**
computational path accepts
- {{< iconify fa6-solid microscope >}} **Key insight**: NFAs can be
"simpler" than equivalent DFAs

:::

::: {.fragment .fade .boxed-content style="font-size: 0.7em;"}

**You can think of NFAs as exploring multiple possibilities simultaneously**! An
NFA is like a DFA that can "clone itself" at decision points. If any clone
reaches an accept state, the entire computation accepts the input! Wait, sound
familiar to the nondeterministic Turing machine? **Oh, don't forget that they are
more expressive, not more powerful!**

:::

## NFA visualization: cloning and choices {transition="convex"}

![Viewing an NFA in light of a TM or a DFA](09-finite-automata_2.png)

::: {.fragment style="margin-top: 0.25em; font-size: 0.975em;"}

- {{< iconify fa6-solid clone >}} **What are connections between an NFA and DFA or TM?**

:::

## Grasping automaton acceptance

::: {.fragment style="margin-top: -0.35em; font-size: 0.825em;"}

- **Accept**: if any clone reaches accept state
- **Reject**: if all clones reject
- **Undefined**: if all clones enter infinite $\epsilon$-loop
- **Essentially, same conception as nondeterministic Turing machines!**
- **Next Step**: Explore a DFA or an NFA that accepts the strings “AA”, “AGA”,
and an “A” followed by any combination of C’s and G’s (provided there is at
least one C or G). **How would we build this finite automaton?**
- **There are different, equivalent ways to build this finite automaton!**
    - Use a blank symbol
    - Use the $\epsilon$-transition
    - Combine both blank symbols and $\epsilon$-transitions

:::

## Using a blank symbol {transition="convex"}

![An NFA that leverages a blank symbol](09-finite-automata_3.png)

## Using the $\epsilon$-transition {transition="convex"}

![An NFA that uses the $\epsilon$-transition](09-finite-automata_4.png)

## Accepting multiples of 2 or 3 letters

![NFA for input strings with length that is a multiple of 2 or 3](09-finite-automata_5.png){.sensible-square-thick-border}

## Understanding the prior NFA

::: {.fragment style="margin-top: 0.25em; font-size: 0.9em;"}

- **Problem**: accept strings of $n$ G's where $n$ is divisible by 2 or
3
- **NFA advantage**: decomposes into two independent checks
- **Top path**: checks divisibility of string length $n$ by 2
- **Bottom path**: checks divisibility of string length $n$ by 3
- **Equivalent DFA**: would be more complex and perhaps less intuitive
- **NFAs often model problems more "naturally"!**
    - Make sure that you see how it uses the blank symbol
    - Confirm that you understand how it uses the $\epsilon$-transition
    - Could you build this NFA as a DFA? **Go ahead, try it out!**

:::

# Converting NFAs to DFAs

::: {.incremental style="margin-top: -0.5em; font-size: 0.9em;"}

- {{< iconify fa6-solid equals >}} **Key theorem**: Every NFA has an equivalent
DFA
- {{< iconify fa6-solid diagram-project >}} **Subset construction**: DFA states
represent sets of NFA states
- {{< iconify fa6-solid arrow-up-right-dots >}} **State explosion**: DFA may
have up to $2^k$ states for $k$ NFA states
- {{< iconify fa6-solid microscope >}} **Implication**: Nondeterminism doesn't
increase computational power for finite automata! Instead, it enables us to
design "simpler" or more "expressive" machines. Get the trade-off?

:::

::: {.fragment .fade .boxed-content style="font-size: 0.8em;"}

**Nondeterminism provides convenience, not power**: any language recognized by
an NFA can also be recognized by a DFA. The DFA may be exponentially larger,
but it can be built and it solves the same problem!

:::

## NFA to DFA conversion algorithm

::: {.incremental style="margin-top: -0.5em; font-size: 0.8em;"}

1. **Create DFA start state**: set containing NFA start state plus all
states reachable via $\epsilon$-transitions
2. **For each DFA state and symbol**: compute the set of NFA states
reachable
3. **Mark DFA states as accepting**: if they contain any NFA accepting
state
4. **Repeat** until no new DFA states discovered
5. **Result**: DFA with states as subsets of NFA states

:::

::: {.fragment .fade .boxed-content style="font-size: 0.8em;"}

- **Subset construction** systematically tracks all possible NFA states. Each DFA
state represents "all places the NFA could be" after reading the input so far.
This construction proves NFAs and DFAs are equally powerful!
- **Key questions**: what would the DFA that arises from this conversion process
look like for a prior NFA? Which one do you prefer? Why?

:::

## Final DFA arising from an NFA {transition="convex"}

![Completed DFA resulting from an original NFA](09-finite-automata_13.png){.sensible-size-thick-border}

## Grasping trade-offs of the DFA

::: {.fragment style="margin-top: -0.25em; font-size: 0.85em;"}

- **What do NFAs and DFAs have in common?**
  - Both are finite automata consisting of:
    - States
    - Transitions
  - Both recognize regular languages
  - Both support the blank symbol
  - Both have a start state and an accepting state
- **Observation**: DFA often has more states than original NFA
- **Trade-off**: clarity versus size in automaton design
- {{< iconify fa6-solid lightbulb >}} **When would you prefer an NFA
over a DFA? Why?**

:::

# Regular expressions

::: {.incremental style="margin-top: -0.5em; font-size: 0.9em;"}

- {{< iconify fa6-solid code >}} **Regular expressions**:
concise pattern description language
- {{< iconify fa6-solid equals >}} **Equivalent to finite automata**:
same power as DFAs or NFAs
- {{< iconify fa6-solid wrench >}} **Practical applications**: text
search, validation, lexical analysis
- {{< iconify fa6-solid microscope >}} **Theoretical importance**:
define regular languages precisely

:::

::: {.fragment .fade .boxed-content style="font-size: 0.8em;"}

{{< iconify fa6-solid rocket >}} **Regular expressions bridge theory and
practice** as they're both a formal mathematical notation for describing
languages and a practical tool used daily by programmers for **pattern
matching** and **text processing**!

:::

## Find an open-source Python project that contains a regular expression! {transition="convex"}

::: fragment

- What did you find? How does it work?
- What are the benefits and limitations?
- **Share the link and a code segment**
- Here is an example from `GatorGrader`:

:::

::: fragment

```python
MULTILINECOMMENT_RE_JAVA = r"""/\*([^*]|[\r\n]|(\*+([^*/]|[\r\n])))*\*+/"""
SINGLELINECOMMENT_RE_JAVA = r"""^(?:[^"/\\]|\"(?:[^\"\\]|\\.)*
\"|/(?:[^/"\\]|\\.)|/\"(?:[^\"\\]|\\.)*\"|\\.)*//(.*)$"""
SINGLELINECOMMENT_RE_PYTHON = r"""^(?:[^"#\\]|\"(?:[^\"\\]|\\.)*\"|
/(?:[^#"\\]|\\.)|/\"(?:[^\"\\]|\\.)*\"|\\.)*#(.*)$"""
MULTILINECOMMENT_RE_PYTHON = r'^[ \t]*"""(.*?)"""[ \t]*$'
```

:::

## Define "pure" regular expressions

![The basics of pure regular expression](09-finite-automata_14.png)

::: fragment

- Define a good starting point for grasping regular expressions
- Help us to think about how they relate to DFAs and NFAs
- Although not exactly how they often appear in programming languages, many of
the concepts are very similar!

:::

## Regular expression operations

![Operations available in regular expressions](09-finite-automata_15.png)

::: fragment

- Build up more useful pure regular expressions with operations. Using
concatenation, alteration, or Kleene star always results in a new regular
expression!

:::

## Key details about regular expression

::: {.fragment style="margin-top: 0.25em; font-size: 0.9em;"}

- **Empty string** $\epsilon$: matches nothing (zero characters)
- **Single character** $a$: matches exactly that character
- **Concatenation** (written as $r_1 r_2$): match $r_1$ then $r_2$
- **Alternation** (written as $r_1 | r_2$): match $r_1$ or $r_2$
- **Kleene star** (written as $r^*$): match $r$ zero or more times
- All regular languages can be created from these operations
- A language is **regular** if some regular expression describes it
- Or, a regular expression **describes** a regular language
- **Let's look at some examples so we better grasp how they work!**

:::

## Regular expression examples

![Examples of pure regular expressions and the language that they describe](09-finite-automata_16.png)

## Pure regular expression notation

::: {.fragment style="margin-top: -0.25em; font-size: 0.85em;"}

- **Pattern matching**: describe sets of strings concisely
- **Practical extensions**: 
    - `.` means any char
    - `+` means one or more
    - `[...]` is a character class
    - `[a-z]` matches any character in range
    - `[^abc]` matches any character except those listed
    - These are all "syntactic sugar" for convenience
- {{< iconify fa6-solid lightbulb >}} **Can you write a regex for email
addresses?**
- {{< iconify fa6-solid rocket >}} **How do you test a regular expressions'
correctness?**

:::

## Regular expressions in Python

```{python}
import re

def test_pattern(pattern: str, test_strings: list) -> None:
    """Test a regex pattern against multiple strings."""
    regex = re.compile(pattern)
    for s in test_strings:
        match = regex.fullmatch(s)
        print(f"'{s}': {'Match' if match else 'No match'}")

# pattern: strings starting with 'A' and ending with 'B'
pattern = r'A.*B'
test_strings = ['AB', 'ACCCB', 'AXYZB', 'ABC', 'BA']
print("Pattern: A.*B (start with A, end with B)")
test_pattern(pattern, test_strings)

# pattern: exactly 3 digits
print("\nPattern: [0-9]{3} (exactly 3 digits)")
pattern2 = r'[0-9]{3}'
test_strings2 = ['123', '456', '12', '1234', 'abc']
test_pattern(pattern2, test_strings2)
```

## Pattern matching for email

```{python}
import re

# pattern for simple email validation
pattern = r'[a-zA-Z0-9]+@[a-zA-Z0-9]+\.[a-zA-Z]+'
test_strings = [
    'user@example.com',
    'test.user@domain.org',
    'invalid@',
    '@invalid.com',
    'no-at-sign.com'
]
print("Email pattern: [a-zA-Z0-9]+@[a-zA-Z0-9]+\\.[a-zA-Z]+")
test_pattern(pattern, test_strings)
```

## Regex and finite automata

::: {.incremental style="margin-top: -0.5em; font-size: 0.9em;"}

- {{< iconify fa6-solid exchange-alt >}} **Two-way conversion**: regex ↔ NFA ↔
DFA
- {{< iconify fa6-solid arrow-right >}} **Regex to NFA**: build NFA
compositionally from operations
- {{< iconify fa6-solid arrow-left >}} **DFA to regex**: simplify DFA by
labeling transitions with regex
- {{< iconify fa6-solid equals >}} **Same power**: all models recognize same
regular languages!

:::

::: {.fragment .fade .boxed-content style="font-size: 0.8em;"}

- **Conversion between models is possible**:
    - Convert a regular expression to a DFA or an NFA
    - Convert a DFA or an NFA to a regular expression

- **Multiple formalisms give different viewpoint**: DFAs are easiest to
simulate, NFAs are easiest to design, and regexes are easiest to program.

:::

# Regular languages

::: {.incremental style="margin-top: -0.5em; font-size: 0.8em;"}

- {{< iconify fa6-solid book >}} **Regular language**: decided by some DFA (or
NFA, or regex)
- {{< iconify fa6-solid equals >}} **Three equivalent definitions**:
    - DFA-decidable
    - NFA-decidable
    - Regex-describable
- {{< iconify fa6-solid circle-question >}} **Key question**: Are all decidable
languages regular?
- {{< iconify fa6-solid xmark >}} **Answer**: No, some decidable languages are
not regular!
- {{< iconify fa6-solid rocket >}} **Key computational hierarchy**: regular
languages are a proper subset of decidable languages. Computational models
differ in power, and resource limitations, like finite memory, restrict what can
be computed!

:::

## Regular languages are decidable

::: {.incremental style="margin-top: -0.5em; font-size: 0.9em;"}

- **Claim**: If a language is regular, then it's decidable
- **Proof**: Every DFA is a special case of Turing machine
- **Therefore**: Any language decided by DFA is decided by TM
- **Implication**: Regular ⊆ Decidable

:::

::: {.fragment .fade .boxed-content style="font-size: 0.85em;"}

**Trivial but important**: the containment Regular ⊆ Decidable is obvious from
definitions. Specifically, we know that a finite automaton is a restricted
Turing machine. Next, we want to explore whether there are decidable languages
that are not regular by exploring the language defined by $G^nT^n$. In a moment
we will also implement this language in Python, further confirming that it is
decidable. Okay, let's dive in!

:::

## $G^nT^n$ is decidable but not regular

::: {.incremental style="margin-top: -0.5em; font-size: 0.85em;"}

- **Language**: $\{G^nT^n : n \geq 0\} = \{\epsilon, GT, GGTT, GGGTTTT,
...\}$
- **Decidable**: Turing machine (or Python program) can count G's and T's
- **Not regular**: DFA has finite states and cannot count unbounded values
- **Proof technique**: suppose DFA exists, derive a logical contradiction
- **Contradiction**: DFA must accept strings it shouldn't
- **Conclusion**: $G^nT^n$ is not a regular language for any $n \geq 0$

:::

::: {.fragment .fade .boxed-content style="font-size: 0.8em;"}

**$G^nT^n$ requires unbounded counting**: a DFA would need different states for
each possible value of $n$, but DFAs have only finitely many states. This proves
some decidable languages are not regular, a key result for this class!

:::

## Explore $G^nT^n$ in Python

```{pyodide}
#| autorun: true
#| max-lines: 6
def GnTn(inString): 
    length = len(inString)
    # length must be even
    if length % 2 != 0: return 'no'
    # split into first half and second half of input
    firstHalf = inString[:length//2]
    secondHalf = inString[length//2:]
    # firstHalf must contain all Gs
    for x in firstHalf:
        if x != 'G': return 'no'
    # secondHalf must contain all Ts
    for x in secondHalf:
        if x != 'T': return 'no'
    return 'yes' 

def testGnTn():
    testvals = [('', 'yes'),
                ('GT', 'yes'),
                ('GGTT', 'yes'),
                ('GGGTTT', 'yes'),
                ('GGGGTTTT', 'yes'),
                ('G', 'no'),
                ('T', 'no'),
                ('TG', 'no'),
                ('GGTTT', 'no'),
                ('TTTTTT', 'no'),
                ('GGTTTT', 'no'),
            ]
    for (inString, solution) in testvals:
        val = GnTn(inString)
        print(inString, ': ', val)
        assert val == solution

testGnTn()
```

## Proof visualization: $G^nT^n$ not regular

![Pigeonhole principle applied to DFA](09-finite-automata_31.png)

::: {.fragment style="margin-top: 0.25em; font-size: 0.9em;"}

- **Pigeonhole principle**: more G's than states forces a cycle
- **Cycle traversal**: can repeat or skip, creating wrong string
- **"Pumping" the cycle**: generates strings not in language
- {{< iconify fa6-solid lightbulb >}} **This technique generalizes to
the pumping lemma!**

:::

## Compare Turing machines and DFAs

::: fragment

- The finite memory of a DFA that makes it more limited than a Turing machine.
But Turing machines also have a finite number of states. **Why don’t they have
the same problem?**
- They use a tape to recall as much information as needed!
- They can record infinitely many distinct strings on its tape.
- So although it has a finite set of states, it has infinitely many possible
configurations. **Do you now see the power of unbounded memory in a Turing
machine?**
- Okay, now we are ready to explore the pumping lemma!

:::

# Pumping lemma

::: {.incremental style="margin-top: -0.5em; font-size: 0.9em;"}

- {{< iconify fa6-solid rotate >}} **Pumping**: repeating a substring
zero or more times
- {{< iconify fa6-solid text >}} **Example**: "TGACGT" → pump "AC" →
"TGACACGT" or "TGT"
- {{< iconify fa6-solid circle-check >}} **Still in language**: pumped
string remains valid
- {{< iconify fa6-solid microscope >}} **Key insight**: regular
languages always allow pumping long strings

:::

::: {.fragment .fade .boxed-content style="font-size: 0.8em;"}

**Pumping exploits finite-state limitation**: if a DFA accepts a long
string, it must revisit states, creating a cycle that can be repeated
or skipped. This forced repetition is the essence of pumping!

:::

## Pumping example in language

![Pumping substrings in ATC*|TG(AC)*GT](09-finite-automata_33.png)

::: {.fragment style="margin-top: 0.25em; font-size: 0.9em;"}

- **Original string**: underlined portion can be repeated
- **Pumped versions**: repeat 0, 1, 2, or more times
- **All accepted**: because pumped portion corresponds to DFA cycle
- {{< iconify fa6-solid lightbulb >}} **Regular languages have this
property!**

:::

## Formal definition of pumping

![Pumping lemma definition](09-finite-automata_34.png)

::: {.fragment style="margin-top: 0.25em; font-size: 0.9em;"}

- **Decomposition**: string $w = xyz$ where $y$ is the pumped part
- **Constraints**: $|y| \geq 1$ (non-empty), $|xy| \leq k$ (early in
string)
- **Pumping**: $xy^iz$ in language for all $i \geq 0$
- {{< iconify fa6-solid lightbulb >}} **Formalization of cycle-based
repetition!**

:::

## The pumping lemma for regular languages

![Pumping lemma statement](09-finite-automata_35.png)

::: {.fragment style="margin-top: 0.25em; font-size: 0.9em;"}

- **Theorem**: If language is regular and infinite, it can be pumped
- **Constant** $k$: depends on the DFA (usually number of states)
- **Every long string**: length ≥ $k$ can be decomposed and pumped
- **Contrapositive**: if no pumping possible, language is not regular
- {{< iconify fa6-solid lightbulb >}} **Main use: prove languages are
not regular!**

:::

## Using pumping lemma to prove non-regularity

::: {.incremental style="margin-top: -0.5em; font-size: 0.85em;"}

1. **Assume** language $L$ is regular
2. **Apply pumping lemma**: get constant $k$ and decomposition $xyz$
3. **Choose specific string** $w \in L$ with $|w| \geq k$
4. **Consider all possible decompositions** satisfying constraints
5. **Show pumping fails**: find $i$ where $xy^iz \notin L$
6. **Contradiction**: therefore $L$ is not regular

:::

::: {.fragment .fade .boxed-content style="font-size: 0.8em;"}

**Proof by contradiction**: the pumping lemma gives us a powerful tool.
To prove $L$ is not regular, show that no matter how we pump, we
eventually generate a string not in $L$. This contradicts regularity!

:::

## Combining regular languages

![Closure properties of regular languages](09-finite-automata_36.png)

::: {.fragment style="margin-top: 0.25em; font-size: 0.9em;"}

- **Union**: $L_1 \cup L_2$ is regular if $L_1$, $L_2$ regular
- **Concatenation**: $L_1 L_2$ is regular if $L_1$, $L_2$ regular
- **Complement**: $\overline{L}$ is regular if $L$ regular
- **Intersection**: $L_1 \cap L_2$ is regular if $L_1$, $L_2$ regular
- **Closure properties**: regular languages closed under these
operations
- {{< iconify fa6-solid lightbulb >}} **Proof exercise: construct DFAs
for operations!**

:::

## Applications of closure properties

::: {.incremental style="margin-top: -0.5em; font-size: 0.9em;"}

- **Proving non-regularity**: if $L$ regular and $\overline{L}$ not
regular, contradiction!
- **SameGT example**: equal numbers of G's and T's is not regular
- **Proof**: combine $G^nT^n$ result with closure properties
- **Java programs**: language of syntactically valid Java is not
regular
- **Practical implication**: need more powerful parsers than DFAs

:::

::: {.fragment .fade .boxed-content style="font-size: 0.8em;"}

**Closure properties are proof tools**: they let us build new
non-regularity results from known ones. Programming language syntax
generally requires context-free grammars (more powerful than regular
expressions) for parsing!

:::

## Summary: finite automata and regular languages

::: {.incremental style="margin-top: -0.5em; font-size: 0.85em;"}

- **DFAs**: simplest computational model, deterministic state
transitions
- **NFAs**: allow nondeterminism and $\epsilon$-transitions, equal
power to DFAs
- **Regular expressions**: concise notation, equivalent to DFAs/NFAs
- **Regular languages**: decided by DFAs, described by regex
- **Pumping lemma**: tool for proving languages are not regular
- **Closure properties**: regular languages closed under many
operations
- **Hierarchy**: Regular ⊂ Decidable ⊂ All Languages

:::

::: {.fragment .fade .boxed-content style="font-size: 0.8em;"}

**Finite automata reveal computational limits**: despite their
simplicity and practical utility, they cannot recognize all decidable
languages. Understanding these limits helps proofgrammers choose
appropriate tools for different computational tasks!

:::

## Proofgrammer perspective on finite automata

::: {.incremental style="margin-top: -0.5em; font-size: 0.9em;"}

- {{< iconify fa6-solid code >}} **Implement**: DFA simulators, NFA to
DFA converters, regex matchers
- {{< iconify fa6-solid file-code >}} **Prove**: use pumping lemma to
show languages are not regular
- {{< iconify fa6-solid microscope >}} **Analyze**: when are finite
automata sufficient?
- {{< iconify fa6-solid wrench >}} **Apply**: lexical analysis,
protocol verification, pattern matching
- {{< iconify fa6-solid graduation-cap >}} **Understand**: limits of
computational models

:::

::: {.fragment .fade .boxed-content style="font-size: 0.8em;"}

**Proofgrammers master both theory and practice**: build simulators to
understand automata behavior, write formal proofs of non-regularity,
and apply these insights to real-world problems like text processing
and input validation!

:::

# Questions for discussion

::: {.incremental style="margin-top: -0.5em; font-size: 0.9em;"}

- Why are regular expressions so widely used in practice?
- When would you prefer an NFA over a DFA in your design?
- Can you think of a language that is decidable but not regular?
- How do closure properties help in proving non-regularity?
- What practical applications have you seen for finite automata?
- How does the pumping lemma exploit the finite-state nature of DFAs?

:::

::: {.fragment .fade .boxed-content style="font-size: 0.8em;"}

**Explore these questions in your teams**: finite automata connect
theory to practice in numerous ways. Discuss how resource limitations
affect computability and how you might apply these concepts in your own
programming projects!

:::
